{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/makeschoolloaner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/makeschoolloaner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionID</th>\n",
       "      <th>Question</th>\n",
       "      <th>DocumentID</th>\n",
       "      <th>DocumentTitle</th>\n",
       "      <th>SentenceID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-0</td>\n",
       "      <td>A partly submerged glacier cave on Perito More...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-1</td>\n",
       "      <td>The ice facade is approximately 60 m high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-2</td>\n",
       "      <td>Ice formations in the Titlis glacier cave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-3</td>\n",
       "      <td>A glacier cave is a cave formed within the ice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>how are glacier caves formed?</td>\n",
       "      <td>D1</td>\n",
       "      <td>Glacier cave</td>\n",
       "      <td>D1-4</td>\n",
       "      <td>Glacier caves are often called ice caves , but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QuestionID                       Question DocumentID DocumentTitle  \\\n",
       "0         Q1  how are glacier caves formed?         D1  Glacier cave   \n",
       "1         Q1  how are glacier caves formed?         D1  Glacier cave   \n",
       "2         Q1  how are glacier caves formed?         D1  Glacier cave   \n",
       "3         Q1  how are glacier caves formed?         D1  Glacier cave   \n",
       "4         Q1  how are glacier caves formed?         D1  Glacier cave   \n",
       "\n",
       "  SentenceID                                           Sentence  Label  \n",
       "0       D1-0  A partly submerged glacier cave on Perito More...      0  \n",
       "1       D1-1          The ice facade is approximately 60 m high      0  \n",
       "2       D1-2          Ice formations in the Titlis glacier cave      0  \n",
       "3       D1-3  A glacier cave is a cave formed within the ice...      1  \n",
       "4       D1-4  Glacier caves are often called ice caves , but...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('WikiQA-train.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionID       0\n",
       "Question         0\n",
       "DocumentID       0\n",
       "DocumentTitle    0\n",
       "SentenceID       0\n",
       "Sentence         0\n",
       "Label            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Info about DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20347 entries, 0 to 20346\n",
      "Data columns (total 7 columns):\n",
      "QuestionID       20347 non-null object\n",
      "Question         20347 non-null object\n",
      "DocumentID       20347 non-null object\n",
      "DocumentTitle    20347 non-null object\n",
      "SentenceID       20347 non-null object\n",
      "Sentence         20347 non-null object\n",
      "Label            20347 non-null int64\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Text\n",
    "\n",
    "This function uses regex to remove HTML tags, punctuation, and numbers. It also converts words to lowercase and appends them to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(col):\n",
    "    \n",
    "    clean_txt = []\n",
    "    \n",
    "    for w in col:\n",
    "        words = re.sub('<.*?>', '', w)\n",
    "        words = re.sub(r'[^\\w\\s]', '', words)\n",
    "        words = re.sub(r'\\d+', '', words)\n",
    "        words = words.lower()\n",
    "        \n",
    "        if words != '':\n",
    "            clean_txt.append(words)\n",
    "            \n",
    "    return clean_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses NLTK to convert sentences into word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_w(words):    \n",
    "    tokens = [nltk.word_tokenize(w) for w in words if w != '']\n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize Word Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_w(words):\n",
    "    new_words = []\n",
    "    for tokens in words:\n",
    "        for word in tokens:\n",
    "            new_words.append(lemmatizer.lemmatize(word))\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'are', 'glacier', 'cave', 'formed', 'how', 'are', 'glacier', 'cave', 'formed']\n"
     ]
    }
   ],
   "source": [
    "clean_w = clean_data(df['Question'])\n",
    "tokens = tokenize_w(clean_w)\n",
    "lemms = lemmatize_w(tokens)\n",
    "print(lemms[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Processed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_processed(txt):\n",
    "    sort = sorted(list(set(txt)))\n",
    "    return sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(lst):\n",
    "    unique_classes = []\n",
    "    for i in lst:\n",
    "        tags = tuple(i)\n",
    "        if tags not in unique_classes:\n",
    "            unique_classes.append(tags)\n",
    "    return unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs Questions with Corresponding Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_question(col1, col2):\n",
    "    clean_docs = []\n",
    "    clean_w = clean_data(col1)\n",
    "    clean_tags = clean_data(col2)\n",
    "    \n",
    "    for i, j in zip(clean_w, clean_tags):\n",
    "        clean_docs.append((i, j))\n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('how are glacier caves formed', 'glacier cave'), ('how are glacier caves formed', 'glacier cave'), ('how are glacier caves formed', 'glacier cave'), ('how are glacier caves formed', 'glacier cave'), ('how are glacier caves formed', 'glacier cave'), ('how are the directions of the velocity and force vectors related in a circular motion', 'circular motion'), ('how are the directions of the velocity and force vectors related in a circular motion', 'circular motion'), ('how are the directions of the velocity and force vectors related in a circular motion', 'circular motion'), ('how are the directions of the velocity and force vectors related in a circular motion', 'circular motion'), ('how are the directions of the velocity and force vectors related in a circular motion', 'circular motion')]\n"
     ]
    }
   ],
   "source": [
    "test = tag_question(df['Question'], df['DocumentTitle'])\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(col):\n",
    "    clean_w = clean_data(col)\n",
    "    tokens = tokenize_w(clean_w)\n",
    "    lemms = lemmatize_w(tokens)\n",
    "    w_clean = sort_processed(lemms)\n",
    "    return w_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'ability', 'able', 'abolished', 'abortion', 'about', 'abraham', 'academy', 'acarina', 'accessory', 'accidentally', 'accompanied', 'according', 'account', 'accused', 'acid', 'acquire', 'acquisition', 'acre', 'acronym', 'act', 'activated', 'active', 'activity', 'actor', 'actual', 'adam', 'adapter', 'add', 'address', 'adem', 'adenosine', 'adiabatic', 'adjustment', 'administered', 'administrative', 'adult', 'advantage', 'advisor', 'advocacy', 'aerosmith', 'affair', 'affect', 'affected', 'affinity', 'afge', 'afghanistan', 'africa', 'african', 'afrotc', 'after', 'afterimage', 'against', 'age', 'agency', 'agent', 'aggression', 'agi', 'agreement', 'aid', 'air', 'aircraft', 'airline', 'airplane', 'airport', 'ala', 'alarm', 'alaska', 'album', 'alcohol', 'aleppo', 'alert', 'algoma', 'algorithm', 'alighieri', 'alive', 'alkaline', 'alkaseltzer', 'all', 'allan', 'allow', 'along', 'alpine', 'alright', 'alt', 'aluminum', 'alvin', 'always', 'am', 'amber', 'ambersnail', 'amendment', 'america', 'american', 'ami', 'amitriptyline', 'amoled', 'amount', 'amoxicillin']\n"
     ]
    }
   ],
   "source": [
    "words = preprocessing(df['Question'])\n",
    "print(words[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pickle Files and Storing Variables for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'words' (list)\n",
      "Stored 'classes' (list)\n",
      "Stored 'unique_classes' (list)\n",
      "Stored 'documents' (list)\n",
      "Stored 'lemmatizer' (WordNetLemmatizer)\n"
     ]
    }
   ],
   "source": [
    "words = preprocessing(df['Question'])\n",
    "classes = preprocessing(df['DocumentTitle'])\n",
    "unique_classes = unique(classes)\n",
    "documents = tag_question(df['Question'], df['DocumentTitle'])\n",
    "\n",
    "%store words\n",
    "%store classes\n",
    "%store unique_classes\n",
    "%store documents\n",
    "%store lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
